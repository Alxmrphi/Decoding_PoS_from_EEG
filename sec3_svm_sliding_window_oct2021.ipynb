{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!del saved_models SVM_unigram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "n_avg = 1, method = tfr\n",
      "Method =  tfr\n",
      "Found files: ['tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file0.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file1.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file10.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file11.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file12.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file13.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file14.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file15.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file16.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file17.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file18.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file19.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file2.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file20.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file21.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file22.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file23.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file24.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file25.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file26.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file27.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file28.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file29.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file3.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file30.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file31.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file32.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file33.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file34.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file35.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file4.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file5.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file6.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file7.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file8.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_train_file9.tfrecords']\n",
      "data shape: (176, 64)\n",
      "Found files: ['tfrecords_numpy_matching\\\\unigram_6class_avg1_dev_file0.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_dev_file1.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_dev_file2.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_dev_file3.tfrecords']\n",
      "data shape: (176, 64)\n",
      "Found files: ['tfrecords_numpy_matching\\\\unigram_6class_avg1_test_file0.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_test_file1.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_test_file2.tfrecords', 'tfrecords_numpy_matching\\\\unigram_6class_avg1_test_file3.tfrecords']\n",
      "data shape: (176, 64)\n",
      "Running window: 0 to 16\n",
      "(0-16): score: 22.539489266814613%\n",
      "Running window: 4 to 20\n",
      "(4-20): score: 21.439431119836122%\n",
      "Running window: 8 to 24\n",
      "(8-24): score: 20.96071878200751%\n",
      "Running window: 12 to 28\n",
      "(12-28): score: 21.25578802492318%\n",
      "Running window: 16 to 32\n",
      "(16-32): score: 21.03713671474906%\n",
      "Running window: 20 to 36\n",
      "(20-36): score: 21.820587231136905%\n",
      "Running window: 24 to 40\n",
      "(24-40): score: 22.91077639552748%\n",
      "Running window: 28 to 44\n",
      "(28-44): score: 22.408791929839534%\n",
      "Running window: 32 to 48\n",
      "(32-48): score: 23.896341008023214%\n",
      "Running window: 36 to 52\n",
      "(36-52): score: 24.639048630078523%\n",
      "Running window: 40 to 56\n",
      "(40-56): score: 24.33597750938887%\n",
      "Running window: 44 to 60\n",
      "(44-60): score: 26.735807336121542%\n",
      "Running window: 48 to 64\n",
      "(48-64): score: 26.987799803687263%\n",
      "Running window: 52 to 68\n",
      "(52-68): score: 25.297203076988733%\n",
      "Running window: 56 to 72\n",
      "(56-72): score: 26.04884612922499%\n",
      "Running window: 60 to 76\n",
      "(60-76): score: 24.31437243939911%\n",
      "Running window: 64 to 80\n",
      "(64-80): score: 25.86433616421987%\n",
      "Running window: 68 to 84\n",
      "(68-84): score: 24.736871585865483%\n",
      "Running window: 72 to 88\n",
      "(72-88): score: 24.021170301297374%\n",
      "Running window: 76 to 92\n",
      "(76-92): score: 23.221515982417205%\n",
      "Running window: 80 to 96\n",
      "(80-96): score: 22.853296240184363%\n",
      "Running window: 84 to 100\n",
      "(84-100): score: 22.548891473199042%\n",
      "Running window: 88 to 104\n",
      "(88-104): score: 23.556394567258447%\n",
      "Running window: 92 to 108\n",
      "(92-108): score: 22.629243662512806%\n",
      "Running window: 96 to 112\n",
      "(96-112): score: 23.198110489928304%\n",
      "Running window: 100 to 116\n",
      "(100-116): score: 24.229019076476614%\n",
      "Running window: 104 to 120\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "import argparse\n",
    "\n",
    "#my_parser = argparse.ArgumentParser()\n",
    "\n",
    "#my_parser.add_argument('-start', help='starting time point', required=True)\n",
    "#my_parser.add_argument('-window_size', help='size of window', required=True)\n",
    "#my_parser.add_argument('-run_num', help='which number run this is', required=True)\n",
    "#args = my_parser.parse_args()\n",
    "#start = int(args.start)\n",
    "#window_size = int(args.window_size)\n",
    "#print(window_size)\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "\n",
    "BATCH_SIZE=512\n",
    "n_electrodes = 64\n",
    "n_timepoints = 176\n",
    "window_shift = 4\n",
    "window_size = 16\n",
    "N_AVG = 1\n",
    "category = \"unigram_6class\"\n",
    "classes = [i for i in range(6)]\n",
    "n_epoch = 3\n",
    "model_type = \"SVM\"  \n",
    "method = \"tfr\" # \"numpy\" # or \"tfr\"\n",
    "run_num = 0\n",
    "filename_stem = \"unigram_6class\"\n",
    "\n",
    "print(f'n_avg = {N_AVG}, method = {method}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------- TFRecord functionality START\n",
    "def _float_feature_seq(eeg_channel):\n",
    "    \"\"\" Convert sequence of EEG values to tf.train.FeatureList \"\"\"\n",
    "    feature_list = tf.train.FeatureList(feature=[\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(\n",
    "            value=eeg_channel))])\n",
    "    \n",
    "    return feature_list\n",
    "\n",
    "def _int_feature_scalar(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def encode_single_example(eeg_data: np.array, label: int):\n",
    "    \"\"\" TFRecords: process single EEG trial as a SequenceExample\"\"\"\n",
    "    #print(eeg_data.shape)\n",
    "    eeg_data_flat = eeg_data.copy().reshape((-1, 1))\n",
    "    \n",
    "    fl_dict = {'eeg_data':_float_feature_seq(eeg_data_flat)}\n",
    "    label_dict = {'label':  _int_feature_scalar(label)}\n",
    "    \n",
    "    label_features = tf.train.Features(feature=label_dict)\n",
    "    \n",
    "    #print(f'label_features : {label_features}')\n",
    "    \n",
    "    feature_lists = tf.train.FeatureLists(feature_list=fl_dict)\n",
    "    protobuff = tf.train.SequenceExample(context=label_features,\n",
    "                                         feature_lists=feature_lists)\n",
    "\n",
    "    protobuff_serialised = protobuff.SerializeToString()\n",
    "    \n",
    "    return protobuff_serialised\n",
    "\n",
    "\n",
    "def decode_single_example(serialised_example, start_window, end_window,\n",
    "                           total_timepoints, n_electrodes):\n",
    "\n",
    "    data_dim = total_timepoints * n_electrodes\n",
    "\n",
    "    context_desc = {'label': tf.io.FixedLenFeature([], dtype=tf.int64)}\n",
    "    feature_desc = {\n",
    "        'eeg_data': tf.io.FixedLenSequenceFeature([data_dim], dtype=tf.float32)\n",
    "    }\n",
    "\n",
    "    context, data = tf.io.parse_single_sequence_example(\n",
    "        serialized=serialised_example,\n",
    "        context_features=context_desc,\n",
    "        sequence_features=feature_desc,\n",
    "        name='parsing_single_seq_example')\n",
    "\n",
    "    data = data['eeg_data']\n",
    "    data = tf.reshape(data, (n_electrodes, total_timepoints))\n",
    "    data = tf.transpose(data, (1,0))\n",
    "    data = tf.reshape(data, (total_timepoints, 64))\n",
    "    \n",
    "    print(f'data shape: {data.shape}')\n",
    "    data = data[start_window:end_window, :] # Extract (potential sub-window)\n",
    "    WINDOW_LENGTH = end_window - start_window\n",
    "    data = tf.reshape(data, (1, WINDOW_LENGTH * n_electrodes))\n",
    "\n",
    "    label = context['label']\n",
    "    label = tf.cast(label, tf.int32)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "def get_dataset(file_regex, folder, batch_size, repeat,\n",
    "               start_window, end_window, total_timepoints,\n",
    "               n_electrodes):\n",
    "    \n",
    "    decode_single_example_fn = partial(decode_single_example,\n",
    "                                       start_window=start_window,\n",
    "                                       end_window=end_window,\n",
    "                                       total_timepoints=total_timepoints,\n",
    "                                       n_electrodes=n_electrodes)\n",
    "    \n",
    "    files = list(pathlib.Path(folder).glob(file_regex))\n",
    "    assert len(files) > 0, f\"No files found for: {file_regex}\"\n",
    "    files = [str(x) for x in files]\n",
    "    print(f'Found files: {files}')\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads=1)\n",
    "    dataset = dataset.map(decode_single_example_fn, num_parallel_calls=1)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(repeat)\n",
    "\n",
    "    return dataset\n",
    "# ------- TFRecord functionality END\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to run model\n",
    "def run_model_tfr(train_ds, dev_ds, test_ds):\n",
    "    \n",
    "    all_dev_scores = [] # to store all window-level dev scores for this  run\n",
    "    \n",
    "    for start_loc in range(0, n_timepoints, window_shift):\n",
    "        \n",
    "        end_loc = start_loc + window_size\n",
    "        window_begin = start_loc * n_electrodes\n",
    "        window_end = end_loc * n_electrodes\n",
    "        print(f'Running window: {start_loc} to {end_loc}')\n",
    "        \n",
    "        score = 0\n",
    "        best_score = 0\n",
    "        best_global_dev = -1\n",
    "        best_test = 0\n",
    "        SGD_clf = SGDClassifier(loss='hinge', tol=1e-3, alpha=0.75)\n",
    "\n",
    "        for i, (X, y) in enumerate(train_ds):\n",
    "\n",
    "            #print('Printing X shape and y shape [before]')\n",
    "            #print(tf.shape(X))\n",
    "            #print(tf.shape(y))\n",
    "            #print(np.shape(X))\n",
    "            #print(np.shape(y))\n",
    "            \n",
    "            #print('X shape before selecting window', X.shape)\n",
    "            # (512, 1, 1024)\n",
    "\n",
    "            #X = tf.squeeze(X) # remove superfluous dimension\n",
    "            X = X[:, 0, window_begin:window_end] # get right window\n",
    "            \n",
    "            #print('X shape after selecting window', X.shape)\n",
    "            # (512, 1024)\n",
    "\n",
    "            #print('Printing X shape and y shape [after squeeze before slice]')\n",
    "            #print(tf.shape(X))\n",
    "            #print(tf.shape(y))\n",
    "            #print(np.shape(X))\n",
    "            #print(np.shape(y))\n",
    "\n",
    "            #X = tf.slice(X, begin=[window_begin], size=[window_end-window_begin])\n",
    "\n",
    "            #print('Printing X shape and y shape [after]')\n",
    "            #print(tf.shape(X))\n",
    "            #print(tf.shape(y))\n",
    "            #print(np.shape(X))\n",
    "            #print(np.shape(y))\n",
    "            \n",
    "            SGD_clf.partial_fit(X, y, classes=classes)\n",
    "\n",
    "            dev_scores = []\n",
    "            for i, (X_dev, y_dev) in enumerate(dev_ds):\n",
    "\n",
    "                #X_dev = tf.squeeze(X_dev)\n",
    "                #X_dev = X_dev[:, window_begin:window_end]\n",
    "                \n",
    "                \n",
    "                X_dev = X_dev[:, 0, window_begin:window_end] # get right window\n",
    "                \n",
    "\n",
    "                dev_score = SGD_clf.score(X_dev, y_dev)\n",
    "                dev_scores.append(dev_score)\n",
    "              \n",
    "            dev_score = np.mean(dev_scores)\n",
    "            #print(f'{model_type} : epoch ({i}), dev score = {dev_score*100}%')\n",
    "\n",
    "            if dev_score > best_score:\n",
    "                best_score = score\n",
    "                pickle.dump(SGD_clf,\n",
    "                    open(os.path.join(\"saved_models\",\n",
    "                      \"{}_avg{}_start{}_end{}_run{}.pkl\".format(category, N_AVG,\n",
    "                                                                start_loc, end_loc, run_num)), \"wb\"))\n",
    "\n",
    "            if dev_score > best_global_dev:\n",
    "                best_global_dev = score\n",
    "                #best_test = SGD_clf.score(test_data, test_labels)\n",
    "\n",
    "        model = pickle.load(\n",
    "            open(os.path.join(\"saved_models\",\n",
    "                              \"{}_avg{}_start{}_end{}_run{}.pkl\".format(category, N_AVG,\n",
    "                                                                        start_loc, end_loc, run_num)), \"rb\"))\n",
    "        \n",
    "        \n",
    "        dev_scores = []\n",
    "        for i, (X_dev, y_dev) in enumerate(dev_ds):\n",
    "            \n",
    "            #print('X_dev shape before selecting window', X_dev.shape)              \n",
    "            \n",
    "            #X_dev = tf.squeeze(X_dev)\n",
    "            #X_dev = X_dev[:, window_begin:window_end]\n",
    "            X_dev = X_dev[:, 0, window_begin:window_end] # get right window\n",
    "            \n",
    "            #print('X_dev shape after selecting window', X_dev.shape)\n",
    "              \n",
    "            dev_score = model.score(X_dev, y_dev)\n",
    "            dev_scores.append(dev_score)\n",
    "              \n",
    "        dev_score = np.mean(dev_scores)\n",
    "        print(f'({start_loc}-{end_loc}): score: {dev_score*100}%')\n",
    "        all_dev_scores.append(dev_score)\n",
    "\n",
    "\n",
    "    print(all_dev_scores)\n",
    "    \n",
    "    return best_global_dev, best_test, score, model, all_dev_scores\n",
    "\n",
    "if method == \"tfr\":\n",
    "    print(\"Method = \", method)\n",
    "    get_dataset_fn = partial(get_dataset,\n",
    "                            folder=\".\",\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            start_window=0, \n",
    "                            end_window=176,\n",
    "                            total_timepoints=176,\n",
    "                            repeat=4,\n",
    "                            n_electrodes=64)\n",
    "\n",
    "    folder = \"./tfrecords_numpy_matching/\"\n",
    "    train_ds = get_dataset_fn(folder=folder,\n",
    "                            file_regex=f\"unigram_6class_avg{N_AVG}_train*.tfrecords\")\n",
    "\n",
    "    dev_ds = get_dataset_fn(folder=folder,\n",
    "                            file_regex=f\"unigram_6class_avg{N_AVG}_dev*.tfrecords\")\n",
    "\n",
    "    test_ds = get_dataset_fn(folder=folder,\n",
    "                            file_regex=f\"unigram_6class_avg{N_AVG}_test*.tfrecords\")\n",
    "\n",
    "    best_global_dev, best_test, score, SGD_clf, all_dev_scores = run_model_tfr(train_ds, dev_ds, test_ds)\n",
    "\n",
    "elif method == \"numpy\":\n",
    "    print(\"Method = \", method)\n",
    "    run_model_numpy(train_data, train_labels,dev_data, dev_labels,test_data, test_labels)\n",
    "else:\n",
    "    raise Exception(\"Method not understood\")\n",
    "\n",
    "print(\"Final Scores\")\n",
    "print(all_dev_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
